# Backend - Chatbot Multiusu√°rio com Gemini e FastAPI

Este √© o servi√ßo de backend para o projeto **Chatbot Multiusu√°rio**, uma API RESTful desenvolvida com **FastAPI** que gerencia sess√µes de conversa e interage com o modelo **Gemini 2.5 Flash** da Google. A arquitetura √© desenhada para ser limpa, eficiente e pronta para implanta√ß√£o em containers (Docker) em ambientes como o AWS EC2.

---

## üìú Funcionalidades

### Gerenciamento de Sess√£o (Multiusu√°rio)
- **Cria√ß√£o de Sess√£o:** Rota para gerar um novo e √∫nico `session_id` (UUID) para cada usu√°rio/aba de navegador.  
- **Hist√≥rico em Mem√≥ria:** Armazenamento do hist√≥rico de conversas em um dicion√°rio (em mem√≥ria) associado ao `session_id`.  
- **Contexto de Conversa:** Preserva√ß√£o do contexto, enviando o hist√≥rico completo (mensagens anteriores) junto com a nova pergunta do usu√°rio para o LLM.

### Servi√ßo de LLM (Large Language Model)
- **Integra√ß√£o Gemini:** Uso do modelo `gemini-2.5-flash` via `langchain-google-genai` para gera√ß√£o de respostas.  
- **Formato de Comunica√ß√£o:** Convers√£o do hist√≥rico de sess√£o para o formato aceito pela API do Gemini/LangChain.  
- **Sa√≠da Padronizada:** O modelo sempre retorna a resposta como uma string em Markdown, renderizada no frontend.

---

## üéØ Casos de Uso

| Caso de Uso | Descri√ß√£o |
|-------------|-----------|
| **UC-01: Iniciar Nova Sess√£o** | Um usu√°rio acessa a p√°gina e solicita uma nova sess√£o, obtendo um `session_id` √∫nico. |
| **UC-02: Enviar Mensagem** | Um usu√°rio envia uma mensagem ao chatbot. |
| **UC-03: Manter Contexto** | O sistema envia o hist√≥rico completo dessa sess√£o ao Gemini, obtendo uma resposta contextualizada. |
| **UC-04: Salvar Intera√ß√£o** | A pergunta do usu√°rio e a resposta do chatbot s√£o salvas no hist√≥rico. |
| **UC-05: Visualizar Resposta** | O frontend recebe a resposta e renderiza em HTML. |

---

## üèõÔ∏è Arquitetura

A aplica√ß√£o segue uma arquitetura simples e modular:

- **Framework:** FastAPI  
- **LLM Integration:** `langchain-google-genai`  
- **Gerenciamento de Sess√£o:** Classe `SessionManager` usando dicion√°rio em mem√≥ria  
- **Containeriza√ß√£o:** Docker + Uvicorn  
- **Configura√ß√£o:** `python-dotenv` carregando `GEMINI_API_KEY` via `.env`

---

## üöÄ Como Executar (Implanta√ß√£o em AWS EC2 via Docker Hub)

Este projeto √© desenvolvido para implanta√ß√£o containerizada.

### Pr√©-requisitos
- Python (3.11+ recomendado)  
- Docker instalado localmente  
- Conta no Docker Hub  
- Inst√¢ncia AWS EC2 com Docker e porta **8000** liberada  

---

## Passos para Instala√ß√£o e Implanta√ß√£o

### **1. Configurar Vari√°veis de Ambiente**

Crie um arquivo `.env` na raiz:

```bash
GEMINI_API_KEY="SUA_CHAVE_AQUI"
```

---

### 2. Construir e Enviar a Imagem Docker

Substitua `SEU_USUARIO` pelo seu usu√°rio do Docker Hub:

```bash
# 1. Construir a imagem
docker build -t chatbot-gemini-fastapi .

# 2. Taggear para o Docker Hub
docker tag chatbot-gemini-fastapi SEU_USUARIO/chatbot-gemini-fastapi:latest

# 3. Fazer login
docker login

# 4. Enviar a imagem
docker push SEU_USUARIO/chatbot-gemini-fastapi:latest
```

---

### 3. Implantar no AWS EC2

Conectado via SSH ao EC2:

```bash
# 1. Puxar imagem
docker pull SEU_USUARIO/chatbot-gemini-fastapi:latest

# 2. Executar container
docker run -d \
  -p 8000:8000 \
  --name gemini-chatbot-instance \
  --env GEMINI_API_KEY="SUA_CHAVE_AQUI" \
  SEU_USUARIO/chatbot-gemini-fastapi:latest
```
O chatbot estar√° acess√≠vel em: http://<IP_P√öBLICO_DO_EC2>:8000

---

## ‚öôÔ∏è Aspectos T√©cnicos

- **Linguagem:** Python 3.11+  
- **Framework:** FastAPI  
- **Servidor ASGI:** Uvicorn  
- **LLM:** Gemini 2.5 Flash  
- **SDK:** langchain-google-genai  
- **Containeriza√ß√£o:** Docker  
- **Valida√ß√£o:** Pydantic  
- **Depend√™ncias:** `requirements.txt` / Pip  

---

## üîö Endpoints da API

A documenta√ß√£o Swagger estar√° dispon√≠vel em **/docs**.

---

## üìù Rotas de Sess√£o

### **GET /**
Retorna o frontend (`index.html`).

### **GET /new_session**
Cria um novo `session_id`.

**Resposta:**
```json
{
  "session_id": "UUID_AQUI"
}
```

## üí¨ Rota de Chat

### **POST /chat**

Envia a mensagem do usu√°rio, gera a resposta do Gemini e salva no hist√≥rico.

**Corpo da requisi√ß√£o:**
```json
{
  "session_id": "string (UUID da sess√£o)",
  "message": "string (Mensagem do usu√°rio)"
}
```

**Resposta:**
```json
{
  "response": "string (Resposta do Gemini em formato Markdown)"
}
```


